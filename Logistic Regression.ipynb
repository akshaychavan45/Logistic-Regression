{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('https://raw.githubusercontent.com/rashida048/Datasets/master/fraud_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21688</th>\n",
       "      <td>-3.959670</td>\n",
       "      <td>3.297819</td>\n",
       "      <td>-1.079436</td>\n",
       "      <td>-2.290106</td>\n",
       "      <td>-1.405133</td>\n",
       "      <td>2.452586</td>\n",
       "      <td>-4.649235</td>\n",
       "      <td>-12.365464</td>\n",
       "      <td>0.409493</td>\n",
       "      <td>1.251992</td>\n",
       "      <td>...</td>\n",
       "      <td>12.617463</td>\n",
       "      <td>-2.969195</td>\n",
       "      <td>1.755050</td>\n",
       "      <td>0.433324</td>\n",
       "      <td>-0.010827</td>\n",
       "      <td>-0.126613</td>\n",
       "      <td>0.200111</td>\n",
       "      <td>-0.160542</td>\n",
       "      <td>29.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21689</th>\n",
       "      <td>-1.066503</td>\n",
       "      <td>0.539240</td>\n",
       "      <td>0.735343</td>\n",
       "      <td>-0.506800</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>1.141302</td>\n",
       "      <td>-0.127448</td>\n",
       "      <td>-0.119221</td>\n",
       "      <td>-1.870265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162535</td>\n",
       "      <td>-0.576352</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>-0.136154</td>\n",
       "      <td>0.760012</td>\n",
       "      <td>0.048105</td>\n",
       "      <td>-0.017475</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>85.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690</th>\n",
       "      <td>-2.175162</td>\n",
       "      <td>-0.441681</td>\n",
       "      <td>1.883137</td>\n",
       "      <td>-0.267440</td>\n",
       "      <td>1.056972</td>\n",
       "      <td>0.136404</td>\n",
       "      <td>0.113595</td>\n",
       "      <td>-0.055983</td>\n",
       "      <td>0.765616</td>\n",
       "      <td>-0.087568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201561</td>\n",
       "      <td>0.397761</td>\n",
       "      <td>-0.855500</td>\n",
       "      <td>-0.627900</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.515065</td>\n",
       "      <td>0.433089</td>\n",
       "      <td>-0.150291</td>\n",
       "      <td>131.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21691</th>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.694817</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>-0.797912</td>\n",
       "      <td>0.564318</td>\n",
       "      <td>-0.560787</td>\n",
       "      <td>0.805901</td>\n",
       "      <td>0.051453</td>\n",
       "      <td>-0.053817</td>\n",
       "      <td>-0.200190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255891</td>\n",
       "      <td>-0.664635</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>-0.539177</td>\n",
       "      <td>-0.504019</td>\n",
       "      <td>0.155133</td>\n",
       "      <td>0.232846</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21692</th>\n",
       "      <td>-0.312369</td>\n",
       "      <td>0.944738</td>\n",
       "      <td>1.430605</td>\n",
       "      <td>0.627951</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>-0.180406</td>\n",
       "      <td>0.793108</td>\n",
       "      <td>-0.104993</td>\n",
       "      <td>-0.493956</td>\n",
       "      <td>0.344477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.609081</td>\n",
       "      <td>-0.270644</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-0.114185</td>\n",
       "      <td>-0.287989</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>-0.023563</td>\n",
       "      <td>14.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21693 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1      0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2      1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3     -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4     -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21688 -3.959670  3.297819 -1.079436 -2.290106 -1.405133  2.452586 -4.649235   \n",
       "21689 -1.066503  0.539240  0.735343 -0.506800  0.843980 -1.047877  1.141302   \n",
       "21690 -2.175162 -0.441681  1.883137 -0.267440  1.056972  0.136404  0.113595   \n",
       "21691  0.031406  0.694817  0.083233 -0.797912  0.564318 -0.560787  0.805901   \n",
       "21692 -0.312369  0.944738  1.430605  0.627951  0.317725 -0.180406  0.793108   \n",
       "\n",
       "              V8        V9       V10  ...        V21       V22       V23  \\\n",
       "0      -0.069246 -0.266389  0.155315  ...  -0.109627 -0.341365  0.057845   \n",
       "1      -0.626979 -2.274423  1.527782  ...   0.652202  0.272684 -0.982151   \n",
       "2       0.173310 -0.808999  0.775436  ...  -0.003802  0.058556 -0.121177   \n",
       "3      -0.007181 -0.165760  0.869659  ...   0.130648  0.329445  0.927656   \n",
       "4       0.670674 -0.442658  0.133499  ...  -0.312774 -0.799494 -0.064488   \n",
       "...          ...       ...       ...  ...        ...       ...       ...   \n",
       "21688 -12.365464  0.409493  1.251992  ...  12.617463 -2.969195  1.755050   \n",
       "21689  -0.127448 -0.119221 -1.870265  ...  -0.162535 -0.576352 -0.184969   \n",
       "21690  -0.055983  0.765616 -0.087568  ...  -0.201561  0.397761 -0.855500   \n",
       "21691   0.051453 -0.053817 -0.200190  ...  -0.255891 -0.664635  0.018844   \n",
       "21692  -0.104993 -0.493956  0.344477  ...   0.118417  0.609081 -0.270644   \n",
       "\n",
       "            V24       V25       V26       V27       V28  Amount  Class  \n",
       "0      0.499180  0.415211 -0.581949  0.015472  0.018065    4.67      0  \n",
       "1      0.165900  0.360251  0.195321 -0.256273  0.056501  912.00      0  \n",
       "2     -0.304215  0.645893  0.122600 -0.012115 -0.005945    1.00      0  \n",
       "3     -0.049560 -1.892866 -0.575431  0.266573  0.414184   62.10      0  \n",
       "4      0.953062 -0.429550  0.158225  0.076943 -0.015051    2.67      0  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "21688  0.433324 -0.010827 -0.126613  0.200111 -0.160542   29.95      0  \n",
       "21689 -0.136154  0.760012  0.048105 -0.017475  0.092365   85.66      0  \n",
       "21690 -0.627900  0.590977  0.515065  0.433089 -0.150291  131.10      0  \n",
       "21691 -0.539177 -0.504019  0.155133  0.232846  0.079420    4.49      0  \n",
       "21692  0.004333 -0.114185 -0.287989  0.232375 -0.023563   14.90      0  \n",
       "\n",
       "[21693 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=data.iloc[:,:6],data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(X,Y,test_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x_train : The training part of the first sequence ( x ) x_test : The test part of the first sequence ( x ) y_train : The training part of the second sequence ( y ) y_test : The test part of the second sequence ( y )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_train - This includes your all independent variables,these will be used to train the model, also as we have specified the test_size = 0.4 , this means 60% of observations from your complete data will be used to train/fit the model and rest 40% will be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05611144,  0.42711632, -0.02306723, -0.05156048,  0.0310494 ,\n",
       "        0.03659951, -0.04345327,  0.08210426, -0.00212537,  0.00211641,\n",
       "       -0.01879032,  0.0029738 , -0.07175163,  0.00804404, -0.01568234,\n",
       "       -0.02505088, -0.0330111 ,  0.04338797,  0.04656211,  0.01743347])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=clf.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_test - This is remaining 40% portion of the independent variables from the data which will not be used in the training phase and will be used to make predictions to test the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'FunctionTransformer',\n",
       " 'KBinsDiscretizer',\n",
       " 'KernelCenterer',\n",
       " 'LabelBinarizer',\n",
       " 'LabelEncoder',\n",
       " 'MaxAbsScaler',\n",
       " 'MinMaxScaler',\n",
       " 'MultiLabelBinarizer',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OrdinalEncoder',\n",
       " 'PolynomialFeatures',\n",
       " 'PowerTransformer',\n",
       " 'QuantileTransformer',\n",
       " 'RobustScaler',\n",
       " 'SplineTransformer',\n",
       " 'StandardScaler',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_csr_polynomial_expansion',\n",
       " '_data',\n",
       " '_discretization',\n",
       " '_encoders',\n",
       " '_function_transformer',\n",
       " '_label',\n",
       " '_polynomial',\n",
       " 'add_dummy_feature',\n",
       " 'binarize',\n",
       " 'label_binarize',\n",
       " 'maxabs_scale',\n",
       " 'minmax_scale',\n",
       " 'normalize',\n",
       " 'power_transform',\n",
       " 'quantile_transform',\n",
       " 'robust_scale',\n",
       " 'scale']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.read_csv(\"C:/Users/bodak/Downloads/claimants.csv\").dropna()\n",
    "data1\n",
    "\n",
    "data1.head()\n",
    "X,Y=data1.iloc[:,2:],data1['ATTORNEY']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mnx=MinMaxScaler()\n",
    "x_scl=mnx.fit_transform(X)\n",
    "x_scl\n",
    "\n",
    "x_train,x_test,y_train,ytest=sklearn.model_selection.train_test_split(x_scl,Y,test_size=.20)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train.shape\n",
    "clf1=LogisticRegression()\n",
    "clf1.fit(x_train,y_train)\n",
    "\n",
    "pred=clf1.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate The CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASENUM</th>\n",
       "      <th>ATTORNEY</th>\n",
       "      <th>CLMSEX</th>\n",
       "      <th>CLMINSUR</th>\n",
       "      <th>SEATBELT</th>\n",
       "      <th>CLMAGE</th>\n",
       "      <th>LOSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CASENUM  ATTORNEY  CLMSEX  CLMINSUR  SEATBELT  CLMAGE    LOSS\n",
       "0        5         0     0.0       1.0       0.0    50.0  34.940\n",
       "1        3         1     1.0       0.0       0.0    18.0   0.891\n",
       "2       66         1     0.0       1.0       0.0     5.0   0.330\n",
       "3       70         0     0.0       1.0       1.0    31.0   0.037\n",
       "4       96         1     0.0       1.0       0.0    30.0   0.038"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=data1.iloc[:,2:],data1['ATTORNEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.26315789e-01,\n",
       "        2.01262644e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.89473684e-01,\n",
       "        5.13237022e-03],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.26315789e-02,\n",
       "        1.90087786e-03],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.10526316e-01,\n",
       "        5.70263358e-04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.42105263e-02,\n",
       "        1.83002696e-02],\n",
       "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.15789474e-01,\n",
       "        3.96304233e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnx=MinMaxScaler()\n",
    "x_scl=mnx.fit_transform(X)\n",
    "x_scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x_scl,Y,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=clf1.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5636363636363636"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       129\n",
      "           1       0.48      0.59      0.53        91\n",
      "\n",
      "    accuracy                           0.56       220\n",
      "   macro avg       0.57      0.57      0.56       220\n",
      "weighted avg       0.58      0.56      0.57       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583397\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>ATTORNEY</td>     <th>  No. Observations:  </th>  <td>   876</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   871</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 11 Nov 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1580</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:37:10</td>     <th>  Log-Likelihood:    </th> <td> -511.06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -606.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.252e-40</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.4601</td> <td>    0.147</td> <td>    3.140</td> <td> 0.002</td> <td>    0.173</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.4280</td> <td>    0.150</td> <td>    2.851</td> <td> 0.004</td> <td>    0.134</td> <td>    0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.5436</td> <td>    0.592</td> <td>   -0.917</td> <td> 0.359</td> <td>   -1.705</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.7575</td> <td>    0.338</td> <td>    2.240</td> <td> 0.025</td> <td>    0.095</td> <td>    1.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>  -71.7109</td> <td>    6.897</td> <td>  -10.398</td> <td> 0.000</td> <td>  -85.229</td> <td>  -58.193</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               ATTORNEY   No. Observations:                  876\n",
       "Model:                          Logit   Df Residuals:                      871\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Fri, 11 Nov 2022   Pseudo R-squ.:                  0.1580\n",
       "Time:                        11:37:10   Log-Likelihood:                -511.06\n",
       "converged:                       True   LL-Null:                       -606.92\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.252e-40\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.4601      0.147      3.140      0.002       0.173       0.747\n",
       "x2             0.4280      0.150      2.851      0.004       0.134       0.722\n",
       "x3            -0.5436      0.592     -0.917      0.359      -1.705       0.618\n",
       "x4             0.7575      0.338      2.240      0.025       0.095       1.420\n",
       "x5           -71.7109      6.897    -10.398      0.000     -85.229     -58.193\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.Logit(y_train,x_train).fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
